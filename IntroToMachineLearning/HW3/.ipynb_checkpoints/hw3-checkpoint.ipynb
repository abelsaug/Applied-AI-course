{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Multiclass and Linear Models\n",
    "\n",
    "UIC CS 412, Spring 2018\n",
    "\n",
    "_If you have discussed this assignment with anyone, please state their name(s) here: [NAMES]. Keep in mind the expectations set in the Academic Honesty part of the syllabus._\n",
    "\n",
    "There are two parts to this project. The first is on multiclass reductions. The second is on linear models and gradient descent. There is also a third part which gives you an opportunity for extra credit.\n",
    "\n",
    "This assignment is adapted from the github materials for [A Course in Machine Learning](https://github.com/hal3/ciml).\n",
    "\n",
    "## Due Date\n",
    "\n",
    "This assignment is due at 11:59pm Thursday, March 15th. \n",
    "\n",
    "### Files You'll Edit\n",
    "\n",
    "``multiclass.py``: The multiclass classification implementation you need to complete.\n",
    "\n",
    "``gd.py``: The gradient descent file you need to edit.\n",
    "\n",
    "``quizbowl.py``: Multiclass evaluation of the quiz bowl dataset (optional).\n",
    "\n",
    "``predictions.txt``: This file is automatically generated as part of Part 3 (optional).\n",
    "\n",
    "### Files you might want to look at\n",
    "  \n",
    "``binary.py``: Our generic interface for binary classifiers (actually\n",
    "works for regression and other types of classification, too).\n",
    "\n",
    "``datasets.py``: Where a handful of test data sets are stored.\n",
    "\n",
    "``util.py``: A handful of useful utility functions: these will\n",
    "undoubtedly be helpful to you, so take a look!\n",
    "\n",
    "``runClassifier.py``: A few wrappers for doing useful things with\n",
    "classifiers, like training them, generating learning curves, etc.\n",
    "\n",
    "``mlGraphics.py``: A few useful plotting commands\n",
    "\n",
    "``data/*``: All of the datasets we'll use.\n",
    "\n",
    "### What to Submit\n",
    "\n",
    "You will hand in all of the python files listed above as a single zip file **h3.zip** on Gradescope under *Homework 3*.  The programming part constitutes 60% of the grade for this homework. You also need to answer the questions denoted by **WU#** (and a kitten) in this notebook which are the other 40% of your homework grade. When you are done, you should export **hw3.ipynb** with your answers as a PDF file **hw3WrittenPart.pdf**, upload the PDF file to Gradescope under *Homework 3 - Written Part*, and tag each question on Gradescope. \n",
    "\n",
    "Your entire homework will be considered late if any of these parts are submitted late. \n",
    "\n",
    "#### Autograding\n",
    "\n",
    "Your code will be autograded for technical correctness. Please **do\n",
    "not** change the names of any provided functions or classes within the\n",
    "code, or you will wreak havoc on the autograder. We have provided two simple test cases that you can try your code on, see ``run_tests_simple.py``. As usual, you should create more test cases to make sure your code runs correctly.\n",
    "\n",
    "# Part 1: Multiclass Classification *[30% impl, 20% writeup]*\n",
    "\n",
    "In this section, you will explore the differences between three\n",
    "multiclass-to-binary reductions: one-versus-all (OVA), all-versus-all\n",
    "(AVA), and a tree-based reduction (TREE).  The evaluation will be on different datasets from \n",
    "`datasets.py`.\n",
    "\n",
    "The classification task we'll work with is wine classification. The dataset was downloaded from allwines.com. Your job is to predict the type of wine, given the description of the wine. There are two tasks: WineData has 20 different wines, WineDataSmall is just the first five of those (sorted roughly by frequency). You can find the names of the wines both in WineData.labels as well as the file wines.names.\n",
    "\n",
    "To start out, let's import everything and train decision \"stumps\" (aka depth=1 decision trees) on the large data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import multiclass\n",
    "import util\n",
    "from datasets import *\n",
    "import importlib\n",
    "\n",
    "h = multiclass.OVA(20, lambda: DecisionTreeClassifier(max_depth=1))\n",
    "h.train(WineData.X, WineData.Y)\n",
    "P = h.predictAll(WineData.Xte)\n",
    "mean(P == WineData.Yte)\n",
    "# 0.29499072356215211"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means 29% accuracy on this task. The most frequent class is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(mode(WineData.Y))\n",
    "# 1\n",
    "print(WineData.labels[1])\n",
    "# Cabernet-Sauvignon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if you were to always predict label 1, you would get the following accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(WineData.Yte == 1)\n",
    "# 0.17254174397031541"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we're doing a bit (12%) better than that using decision stumps. \n",
    "\n",
    "The default implementation of OVA uses decision tree confidence (probability of prediction) to weigh the votes. You can switch to zero/one predictions to see the effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = h.predictAll(WineData.Xte, useZeroOne=True)\n",
    "mean(P == WineData.Yte)\n",
    "# 0.19109461966604824"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this is markedly worse.\n",
    "\n",
    "Switching to the smaller data set for a minute, we can train, say, depth 3 decision trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = multiclass.OVA(5, lambda: DecisionTreeClassifier(max_depth=3))\n",
    "h.train(WineDataSmall.X, WineDataSmall.Y)\n",
    "P = h.predictAll(WineDataSmall.Xte)\n",
    "print(mean(P == WineDataSmall.Yte))\n",
    "# 0.590809628009\n",
    "print(mean(WineDataSmall.Yte == 1))\n",
    "# 0.407002188184"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So using depth 3 trees we get an accuracy of about 60% (this number varies a bit), versus a baseline of 41%. That's not too terrible, but not great.\n",
    "\n",
    "We can look at what this classifier is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(WineDataSmall.labels[0])\n",
    "#'Sauvignon-Blanc'\n",
    "util.showTree(h.f[0], WineDataSmall.words)\n",
    "#citrus?\n",
    "#-N-> lime?\n",
    "#|    -N-> gooseberry?\n",
    "#|    |    -N-> class 0\t(356.0 for class 0, 10.0 for class 1)\n",
    "#|    |    -Y-> class 1\t(0.0 for class 0, 4.0 for class 1)\n",
    "#|    -Y-> apple?\n",
    "#|    |    -N-> class 1\t(1.0 for class 0, 15.0 for class 1)\n",
    "#|    |    -Y-> class 0\t(2.0 for class 0, 0.0 for class 1)\n",
    "#-Y-> grapefruit?\n",
    "#|    -N-> flavors?\n",
    "#|    |    -N-> class 1\t(4.0 for class 0, 12.0 for class 1)\n",
    "#|    |    -Y-> class 0\t(11.0 for class 0, 5.0 for class 1)\n",
    "#|    -Y-> opens?\n",
    "#|    |    -N-> class 1\t(0.0 for class 0, 14.0 for class 1)\n",
    "#|    |    -Y-> class 0\t(1.0 for class 0, 0.0 for class 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should show the tree that's associated with predicting label 0 (which is stored in h.f[0]). The 1s mean \"likely to be Sauvignon-Blanc\" and the 0s mean \"likely not to be\".\n",
    "\n",
    "Now, go in and complete the AVA implementation in `multiclass.py`. You should be able to train an AVA model on the small data set by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = multiclass.AVA(5, lambda: DecisionTreeClassifier(max_depth=3))\n",
    "h.train(WineDataSmall.X, WineDataSmall.Y)\n",
    "P = h.predictAll(WineDataSmall.Xte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you must implement a \n",
    "tree-based reduction in `multiclass.py`. Most of train is given to you, but predict you\n",
    "must do all on your own. There is a tree class to help you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = multiclass.makeBalancedTree(range(5))\n",
    "print(t)\n",
    "# [[0 1]] [2 [3 4]]]\n",
    "print(t.isLeaf)\n",
    "# False\n",
    "print(t.getRight())\n",
    "# [2 [3 4]]\n",
    "print(t.getRight().getLeft())\n",
    "# 2\n",
    "print(t.getRight().getLeft().isLeaf)\n",
    "# True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to train a MCTree model by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = multiclass.MCTree(t, lambda: DecisionTreeClassifier(max_depth=3))\n",
    "h.train(WineDataSmall.X, WineDataSmall.Y)\n",
    "P = h.predictAll(WineDataSmall.Xte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "## WU1 (10%):\n",
    "Answer A, B, C for both OVA and AVA.\n",
    "\n",
    "(A) What words are most indicative of being Sauvignon-Blanc? Which words are most indicative of not being Sauvignon-Blanc? What about Pinot-Noir (label==2)?\n",
    "\n",
    "(B) Train depth 3 decision trees on the full WineData task (with 20 labels). What accuracy do you get? How long does this take (in seconds)? One of my least favorite wines is Viognier -- what words are indicative of this?\n",
    "\n",
    "(C) Compare the accuracy using zero-one predictions versus using confidence. How much difference does it make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WU1 CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[WU1 ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "## WU2 (10%):\n",
    "Using decision trees of constant depth for each\n",
    "classifier (but you choose it as well as you can!), train AVA, OVA and\n",
    "Tree (using balanced trees) for the wine data. Which does best and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WU2 CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[WU2 ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "## WU-EC1 ExtraCredit (10%):\n",
    "Build a better tree (any way you want) other\n",
    "than the balanced binary tree. Fill in your code for this in\n",
    "`getMyTreeForWine`, which defaults to a balanced tree. It should get\n",
    "at least 5% lower absolute error to get the extra credit. Describe what you\n",
    "did.\n",
    "\n",
    "[YOUR WU-EC1 ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Gradient Descent and Linear Classification *[30% impl, 20% writeup]*\n",
    "\n",
    "To get started with linear models, we will implement a generic\n",
    "gradient descent method.  This should go in `gd.py`, which\n",
    "contains a single (short) function: `gd`. This takes five\n",
    "parameters: the function we're optimizing, it's gradient, an initial\n",
    "position, a number of iterations to run, and an initial step size.\n",
    "\n",
    "In each iteration of gradient descent, we will compute the gradient\n",
    "and take a step in that direction, with step size `eta`.  We\n",
    "will have an *adaptive* step size, where `eta` is computed\n",
    "as `stepSize` divided by the square root of the iteration\n",
    "number (counting from one).\n",
    "\n",
    "Once you have an implementation running, we can check it on a simple\n",
    "example of minimizing the function `x^2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gd.gd(lambda x: x**2, lambda x: 2*x, 10, 10, 0.2)\n",
    "#(1.0034641051795872, array([ 100.        ,   36.        ,   18.5153247 ,   10.95094653,\n",
    "#          7.00860578,    4.72540613,    3.30810578,    2.38344246,\n",
    "#          1.75697198,    1.31968118,    1.00694021]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the \"solution\" found is about 1, which is not great\n",
    "(it should be zero!), but it's better than the initial value of ten!\n",
    "If yours is going up rather than going down, you probably have a sign\n",
    "error somewhere!\n",
    "\n",
    "We can let it run longer and plot the trajectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, trajectory = gd.gd(lambda x: x**2, lambda x: 2*x, 10, 100, 0.2)\n",
    "print(x)\n",
    "# 0.003645900464603937\n",
    "plot(trajectory)\n",
    "show(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now found a value close to zero and you can see that the\n",
    "objective is decreasing by looking at the plot.\n",
    "\n",
    "<img src=\"data/kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "## WU3 (5%):\n",
    "Find a few values of step size where it converges and\n",
    "a few values where it diverges.  Where does the threshold seem to\n",
    "be?\n",
    "\n",
    "[Your WU3 answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "## WU4 (10%):\n",
    "Come up with a *non-convex* univariate\n",
    "optimization problem.  Plot the function you're trying to minimize and\n",
    "show two runs of `gd`, one where it gets caught in a local\n",
    "minimum and one where it manages to make it to a global minimum.  (Use\n",
    "different starting points to accomplish this.)\n",
    "\n",
    "If you implemented it well, this should work in multiple dimensions,\n",
    "too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, trajectory = gd.gd(lambda x: linalg.norm(x)**2, lambda x: 2*x, array([10,5]), 100, 0.2)\n",
    "print(x)\n",
    "# array([ 0.0036459 ,  0.00182295])\n",
    "plot(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our generic linear classifier implementation is\n",
    "in `linear.py`.  The way this works is as follows.  We have an\n",
    "interface `LossFunction` that we want to minimize.  This must\n",
    "be able to compute the loss for a pair `Y` and `Yhat`\n",
    "where, the former is the truth and the latter are the predictions.  It\n",
    "must also be able to compute a gradient when additionally given the\n",
    "data `X`.  This should be all you need for these.\n",
    "\n",
    "There are three loss function stubs: `SquaredLoss` (which is\n",
    "implemented for you!), `LogisticLoss` and `HingeLoss`\n",
    "(both of which you'll have to implement.  My suggestion is to hold off\n",
    "implementing the other two until you have the linear classifier\n",
    "working.\n",
    "\n",
    "The `LinearClassifier` class is a stub implemention of a\n",
    "generic linear classifier with an l2 regularizer.  It\n",
    "is *unbiased* so all you have to take care of are the weights.\n",
    "Your implementation should go in `train`, which has a handful\n",
    "of stubs.  The idea is to just pass appropriate functions\n",
    "to `gd` and have it do all the work.  See the comments inline\n",
    "in the code for more information.\n",
    " \n",
    "Once you've implemented the function evaluation and gradient, we can\n",
    "test this.  We'll begin with a very simple 2D example data set so that\n",
    "we can plot the solutions.  We'll also start with *no\n",
    "regularizer* to help you figure out where errors might be if you\n",
    "have them.  (You'll have to import `mlGraphics` to make this\n",
    "work.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = linear.LinearClassifier({'lossFunction': linear.SquaredLoss(), 'lambda': 0, 'numIter': 100, 'stepSize': 0.5})\n",
    "runClassifier.trainTestSet(f, datasets.TwoDAxisAligned)\n",
    "# Training accuracy 0.91, test accuracy 0.86\n",
    "print(f)\n",
    "# w=array([ 2.73466371, -0.29563932])\n",
    "mlGraphics.plotLinearClassifier(f, datasets.TwoDAxisAligned.X, datasets.TwoDAxisAligned.Y)\n",
    "show(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that even though this data is clearly linearly separable,\n",
    "the *unbiased* classifier is unable to perfectly separate it.\n",
    "\n",
    "If we change the regularizer, we'll get a slightly different\n",
    "solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = linear.LinearClassifier({'lossFunction': linear.SquaredLoss(), 'lambda': 10, 'numIter': 100, 'stepSize': 0.5})\n",
    "runClassifier.trainTestSet(f, datasets.TwoDAxisAligned)\n",
    "# Training accuracy 0.9, test accuracy 0.86\n",
    "print(f)\n",
    "# w=array([ 1.30221546, -0.06764756])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the weights are *smaller*.\n",
    "\n",
    "Now, we can try different loss functions.  Implement logistic loss and\n",
    "hinge loss.  Here are some simple test cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = linear.LinearClassifier({'lossFunction': linear.LogisticLoss(), 'lambda': 10, 'numIter': 100, 'stepSize': 0.5})\n",
    "runClassifier.trainTestSet(f, datasets.TwoDDiagonal)\n",
    "# Training accuracy 0.99, test accuracy 0.86\n",
    "print(f)\n",
    "# w=array([ 0.29809083,  1.01287561])\n",
    "\n",
    "f = linear.LinearClassifier({'lossFunction': linear.HingeLoss(), 'lambda': 1, 'numIter': 100, 'stepSize': 0.5})\n",
    "runClassifier.trainTestSet(f, datasets.TwoDDiagonal)\n",
    "# Training accuracy 0.98, test accuracy 0.86\n",
    "print(f)\n",
    "# w=array([ 1.17110065,  4.67288657])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "## WU5 (5%):\n",
    "For each of the loss functions, train a model on the\n",
    "binary version of the wine data (called WineDataBinary) and evaluate\n",
    "it on the test data. You should use lambda=1 in all cases. Which works\n",
    "best? For that best model, look at the learned weights. Find\n",
    "the *words* corresponding to the weights with the greatest\n",
    "positive value and those with the greatest negative value (this is\n",
    "like LAB3). Hint: look at WineDataBinary.words to get the id-to-word\n",
    "mapping. List the top 5 positive and top 5 negative and explain.\n",
    "\n",
    "[Your WU5 answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Classification with Many Classes *[0% -- up to 15% extra credit]*\n",
    "\n",
    "Finally, we'll do multiclass classification using Scikit-learn functionality. You can find the documentation here: http://scikit-learn.org/stable/modules/multiclass.html.\n",
    "\n",
    "Quiz bowl is a game in which two teams compete head-to-head to answer questions from different areas of knowledge. It lets players interrupt the reading of a question when they know the answer. The goal here is to see how well a classifier performs in predicting the `Answer` of a question when a different portion of the question is revealed.\n",
    "\n",
    "Here's an example question from the development data:\n",
    "\n",
    "    206824,dev,History,Alan Turing,\"This man and Donald Bayley created a secure voice communications machine called \"\"Delilah\"\". ||| The Chinese Room Experiment was developed by John Searle in response to one of this man's namesake tests. ||| He showed that the halting problem was undecidable. ||| He devised a bombe with Gordon Welchman that found the settings of an Enigma machine. ||| One of this man's eponymous machines which can perform any computing task is his namesake \"\"complete.\"\" Name this man, whose eponymous test is used to determine if a machine can exhibit behavior indistinguishable from that of a human.\" \n",
    "\n",
    "The more of the question you get, the easier the problem becomes.\n",
    "\n",
    "The default code below just runs OVA and AVA on top of a linear SVM (it might take a few seconds):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from numpy import *\n",
    "import datasets\n",
    "import importlib\n",
    "\n",
    "importlib.reload(datasets)\n",
    "\n",
    "if not datasets.Quizbowl.loaded:\n",
    "    datasets.loadQuizbowl()\n",
    "\n",
    "print('\\n\\nRUNNING ON EASY DATA\\n')\n",
    "    \n",
    "print('training ova')\n",
    "X = datasets.QuizbowlSmall.X\n",
    "Y = datasets.QuizbowlSmall.Y\n",
    "ova = OneVsOneClassifier(LinearSVC(random_state=0)).fit(X, Y)\n",
    "print('predicting ova')\n",
    "ovaDevPred = ova.predict(datasets.QuizbowlSmall.Xde)\n",
    "print('error = {0}'.format(mean(ovaDevPred != datasets.QuizbowlSmall.Yde)))\n",
    "\n",
    "print('training ava')\n",
    "ava = OneVsRestClassifier(LinearSVC(random_state=0)).fit(X, Y)\n",
    "print('predicting ava')\n",
    "avaDevPred = ava.predict(datasets.QuizbowlSmall.Xde)\n",
    "print('error = {0}'.format(mean(avaDevPred != datasets.QuizbowlSmall.Yde)))\n",
    "\n",
    "print('\\n\\nRUNNING ON HARD DATA\\n')\n",
    "    \n",
    "print('training ova')\n",
    "X = datasets.QuizbowlHardSmall.X\n",
    "Y = datasets.QuizbowlHardSmall.Y\n",
    "ova = OneVsOneClassifier(LinearSVC(random_state=0)).fit(X, Y)\n",
    "print('predicting ova')\n",
    "ovaDevPred = ova.predict(datasets.QuizbowlHardSmall.Xde)\n",
    "print('error = {0}'.format(mean(ovaDevPred != datasets.QuizbowlHardSmall.Yde)))\n",
    "\n",
    "print('training ava')\n",
    "ava = OneVsRestClassifier(LinearSVC(random_state=0)).fit(X, Y)\n",
    "print('predicting ava')\n",
    "avaDevPred = ava.predict(datasets.QuizbowlHardSmall.Xde)\n",
    "print('error = {0}'.format(mean(avaDevPred != datasets.QuizbowlHardSmall.Yde)))\n",
    "\n",
    "savetxt('predictions.txt', avaDevPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run the code above, you should see some statistics of the loaded datasets and the following error rates on two of the datasets `QuizbowlSmall` and `QuizbowlHardSmall` using OVA and AVA:\n",
    "\n",
    "```\n",
    "RUNNING ON EASY DATA\n",
    "\n",
    "training ova\n",
    "predicting ova\n",
    "error = 0.293413\n",
    "training ava\n",
    "predicting ava\n",
    "error = 0.218563\n",
    "\n",
    "\n",
    "RUNNING ON HARD DATA\n",
    "\n",
    "training ova\n",
    "predicting ova\n",
    "error = 0.595808\n",
    "training ava\n",
    "predicting ava\n",
    "error = 0.553892\n",
    "```\n",
    "\n",
    "This is running on a shrunken version of the data (that only contains answers that occur at least 20 times in the data).\n",
    "\n",
    "The first (\"easy\") version is when you get to see the entire question. The second (\"hard\") version is when you only get to use the first two sentences. It's clearly significantly harder to answer!\n",
    "\n",
    "Your task is to achieve the lowest possible error on the development set for `QuizbowlSmall` and `QuizbowlHardSmall`. You will get 5% extra credit for getting lower error (by at least absolute 1%) on *either* dataset than the errors presented above (21.86% for `QuizbowlSmall` and 55.39% for `QuizbowlHardSmall`). \n",
    "\n",
    "You're free to use the training data in any way you want, but you must include your code in `quizbowl.py`, submit your predictions file(s), and a writeup here that says what you did, in order to receive the extra credit. The script `quizbowl.py` includes a command in the last line that saves predictions to a text file `predictions.txt`. You need to edit this line to rename the file to either `predictionsQuizbowlSmall.txt` or `predictionsQuizbowlHardSmall.txt` dependent on the dataset: that's what you upload for the EC. \n",
    "\n",
    "## WU-EC2 (5%):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[YOUR WU-EC2 WRITEUP HERE] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, you can get extra credit for providing the lowest-error solution on the full versions of the easy and hard problems, `Quizbowl` and `QuizbowlHard` in comparison to your classmates' solutions. There will be two separate (hidden) leaderboards for each of these two datasets. You will receive 5% if your solution is the best for the respective dataset (first place), 3% for second place and 1% for third. We will reveal the top three scores for each dataset after the submission period is over, and you are welcome to compete in both. Note that this problem is much harder due to the larger number of class labels. A simple majority label classifier has an error of 99.89%.\n",
    "\n",
    "You're free to use the training data in any way you want, but you must include your code in `quizbowl.py`, submit your predictions file(s) (`predictionsQuizbowl.txt` and/or `predictionsQuizbowlHard.txt`), and a writeup here that says what you did, in order to receive the extra credit.\n",
    "\n",
    "<img src=\"data/kitten.jpeg\" width=\"100px\" align=\"left\" float=\"left\"/>\n",
    "<br><br><br>\n",
    "## WU-EC3 (up to 10%):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[YOUR WU-EC3 WRITEUP HERE] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
